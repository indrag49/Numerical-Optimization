[["conjugate-gradient-methods-1.html", "Chapter 5 Conjugate Gradient Methods 5.1 Introduction to Conjugate Gradient Methods 5.2 Linear Conjugate Gradient Algorithm 5.3 Nonlinear Conjugate Gradient Algorithm", " Chapter 5 Conjugate Gradient Methods This chapter is dedicated to studying the Conjugate Gradient Methods in detail. The Linear and Non-linear versions of the CG methods have been discussed with five sub classes falling under the nonlinear CG method class. The five nonlinear CG methods that have been discussed are: Flethcher-Reeves method, Polak-Ribiere method, Hestenes-Stiefel method, Dai-Yuan method and Hager-Zhang method. Mathematical proofs have been provided wherever necessary. Python implementations of the algorithms have been included along with optimization examples. The chapter ends with introducing a specific Python function called the scipy.optimize.minimize() function that can be used to work with the Polak-Ribiere CG method. 5.1 Introduction to Conjugate Gradient Methods The conjugate gradient methods are frequently used for solving large linear systems of equations and also for solving nonlinear optimization problems. This let us characterize the conjugate gradient methods into two classes: Linear Conjugate Gradient Method: This is an iterative method to solve large linear systems where the coefficient matrices are positive definite. This can be treated as a replacement of the Gaussian elimination method in numerical analysis. nonlinear Conjugate Gradient method: This is used for solving nonlinear optimization problems. We will study five methods under this class: Fletcher-Reeves algorithm, Polak-Ribiere algorithm, Hestenes-Stiefel algorithm, Dai-Yuan algorithm, and Hager-Zhang algorithm. 5.2 Linear Conjugate Gradient Algorithm Suppose we want to find the minimizer of an objective function, having the quadratic form: \\[\\begin{equation} f(\\mathbb{x}) = \\frac{1}{2}\\mathbb{x}^T\\mathbb{A}\\mathbb{x} - \\mathbb{b}^T\\mathbb{x} \\tag{5.1} \\end{equation}\\] where, \\(\\mathbb{A}\\) is a \\(n \\times n\\) symmetric positive definite matrix.The problem can be formulated as: \\[\\begin{equation} \\underset{\\mathbb{x}\\in \\mathbb{R}^n}{\\min} f(\\mathbb{x}) = \\frac{1}{2}\\mathbb{x}^T\\mathbb{A}\\mathbb{x} - \\mathbb{b}^T\\mathbb{x} \\tag{5.2} \\end{equation}\\] Eq. (5.2) can be equivalently stated as the problem of solving the linear system of equations given by: \\[\\begin{equation} \\mathbb{A}\\mathbb{x} = \\mathbb{b} \\tag{5.3} \\end{equation}\\] We use the linear conjugate gradient method to solve Eq. (5.3). The residual of a linear system of equations, given by Eq. (5.3) is defined as: \\[\\begin{equation} r(\\mathbb{x}) = \\mathbb{A}\\mathbb{x} - \\mathbb{b} \\tag{5.4} \\end{equation}\\] Theorem 5.1 The gradient of the objective function given by Eq. (5.1) is equal to the residual of the linear system given by Eq. (5.4). Proof. From Eq. (5.1), we see that the gradient of the objective function is: \\[\\begin{equation} \\nabla f(\\mathbb{x}) = \\mathbb{A}\\mathbb{x} - \\mathbb{b} = r(\\mathbb{x}) \\tag{5.5} \\end{equation}\\] This proves the theorem. 5.2.1 Mutual Conjugacy For a given symmetric positive definite matrix \\(\\mathbb{A}\\), two vectors \\(\\mathbb{v}, \\mathbb{w} \\neq \\mathbb{0} \\in \\mathbb{R}^n\\) are defined to be mutually conjugate if the following condition is satisfied: \\[\\begin{equation} \\mathbb{v}^T\\mathbb{A}\\mathbb{w} = 0 \\tag{5.6} \\end{equation}\\] Theorem 5.2 A set of mutually conjugate vectors \\(\\mathbb{v}_j, j=1, 2, \\ldots\\) with respect to a positive definite symmetric matrix \\(\\mathbb{A}\\), forms a basis in \\(\\mathbb{R}^n\\), i.e., the set is linearly independent. Proof. Above theorem equivalently states that, for \\(\\mathbb{x} \\in \\mathbb{R}^n\\), the following condition is satisfied: \\[\\begin{equation} \\mathbb{x} = \\sum_{j=1}^n\\lambda_j\\mathbb{v}_j \\tag{5.7} \\end{equation}\\] where, \\[\\begin{equation} \\lambda_j = \\frac{\\mathbb{v}_j^T\\mathbb{A}\\mathbb{x}}{\\mathbb{v}_j^T\\mathbb{A}\\mathbb{v}_j} \\tag{5.8} \\end{equation}\\] Let us consider the linear combination, \\[\\begin{equation} \\sum_{j=1}^n c_j\\mathbb{v}_j = \\mathbb{0} \\tag{5.9} \\end{equation}\\] Multiplying the above equation with the matrix \\(\\mathbb{A}\\), we have, \\[\\begin{equation} \\sum_{j=1}^n c_j \\mathbb{A}\\mathbb{v}_j=\\mathbb{0} \\tag{5.10} \\end{equation}\\] Since the vectors \\(\\mathbb{v}_j\\) are mutually conjugate with respect to the matrix \\(\\mathbb{A}\\), from Eq. (5.6), we can write that, \\[\\begin{equation} c_j\\mathbb{v}_j^T\\mathbb{A}\\mathbb{v}_j = 0 \\tag{5.11} \\end{equation}\\] From the facts that \\(\\mathbb{A}\\) is positive definite and that \\(\\mathbb{v}_j\\) never equals \\(\\mathbb{0}\\), from Eq. (5.11) we can state that, \\(c_j=0\\) for \\(j=1, 2, \\ldots, n\\). This proves the fact that the set of vectors \\(\\mathbb{v}_j\\) is linearly independent and may be used as a basis. Therefore, there exists a unique set \\(\\lambda_j, j=1, 2, \\ldots, n\\) for any \\(\\mathbb{x} \\in \\mathbb{R}^n\\), such that Eq. (5.7) is satisfied. The positive definiteness of \\(\\mathbb{A}\\) leads to the fact that, \\[\\begin{equation} \\mathbb{v}_j^T\\mathbb{A}\\mathbb{x} = \\lambda_j\\mathbb{v}_j^T\\mathbb{A}\\mathbb{x} \\tag{5.12} \\end{equation}\\] Finally, from Eq. (5.12) we can write that, \\[\\begin{equation} \\lambda_j = \\frac{\\mathbb{v}_j^T\\mathbb{A}\\mathbb{x}}{\\mathbb{v}_j^T\\mathbb{A}\\mathbb{v}_j} \\tag{5.13} \\end{equation}\\] The proves the theorem. 5.2.2 Conjugate Direction Algorithm For our optimization task, where we aim to minimize the objective function \\(f(\\mathbb{x})\\), where \\(\\mathbb{x} \\in \\mathbb{R}^n\\), let \\(\\mathbb{x}_0\\) be the starting iterate and the conjugate directions be set as \\({\\mathbb{\\delta}_j}, j=1, 2, \\ldots, n-1\\). The successive iterates are generated by following: \\[\\begin{equation} \\mathbb{x}_j = \\mathbb{x}_{j-1}+\\beta_j\\mathbb{\\delta}_j \\tag{5.14} \\end{equation}\\] This \\(\\beta_j\\) is the minimizer of the function \\(f(\\mathbb{x}_{j-1}+\\beta\\delta_j)\\). We will now find the explicit form of \\(\\beta_j\\). From Eq. (5.1) we can write that, \\[\\begin{align} f(x_{j-1}+\\beta \\mathbb{\\delta}_j) &amp;= \\frac{1}{2}[(\\mathbb{x}_{j-1}+\\beta\\mathbb{\\delta}_j)^T\\mathbb{A}(\\mathbb{x}_{j-1}+\\beta\\mathbb{\\delta}_j)] - \\mathbb{b}^T(\\mathbb{x}_{j-1}+\\beta\\mathbb{\\delta}_j) \\nonumber \\\\ &amp;= \\frac{1}{2}[\\mathbb{x}_{j-1}^T\\mathbb{A}\\mathbb{x}_{j-1}+2\\beta\\mathbb{x}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_j + \\beta^2\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j] - \\mathbb{b}^T(\\mathbb{x}_{j-1}+\\beta\\mathbb{\\delta}_j) \\tag{5.15} \\end{align}\\] Now, differentiating Eq. (5.15) with respect to \\(\\beta\\) and setting it to \\(0\\), we get, \\[\\begin{align} &amp; \\frac{\\partial f(\\mathbb{x}_{j-1}+\\beta\\mathbb{\\delta}_j)}{\\partial \\beta} = 0 \\tag{5.16} \\\\ &amp;\\implies \\mathbb{x}_{j-1}^T\\mathbb{A}\\mathbb{x}_{j-1} + \\beta\\mathbb{\\delta}_j\\mathbb{A}\\mathbb{\\delta}_j - \\mathbb{b}^T\\mathbb{\\delta}_j = 0 \\nonumber \\\\ &amp;\\implies (\\mathbb{x}_{j-1}^T\\mathbb{A} - \\mathbb{b}^T)\\mathbb{\\delta}_j + \\beta\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j = 0 \\tag{5.17} \\end{align}\\] Now, from Eq. (5.4) we can write, \\[\\begin{equation} \\mathbb{r}_j^T=(\\mathbb{A}\\mathbb{x}_{j-1}-\\mathbb{b})^T = \\mathbb{x}_{j-1}^T\\mathbb{A} - \\mathbb{b}^T \\tag{5.18} \\end{equation}\\] where, we have used the fact that \\(\\mathbb{A}^T=\\mathbb{A}\\). So, from Eq. (5.17) we can write, \\[\\begin{equation} \\mathbb{r}_j^T\\mathbb{\\delta}_j+\\beta\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j = 0 \\tag{5.19} \\end{equation}\\] This finally fetches us, \\[\\begin{equation} \\beta_j = -\\frac{\\mathbb{r}_j^T\\mathbb{\\delta}_j}{\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j} \\tag{5.20} \\end{equation}\\] Eq. (5.20) is equivalent to the step-length formulation given by Eq. (5.26). Theorem 5.3 The convergence of the conjugate direction algorithm, given by Eq. (5.14) and Eq. (5.20), to its solution, takes place in at most \\(n\\) steps, where \\(\\mathbb{x}_0\\in \\mathbb{R}^n\\) is the given initial iterate. Proof. The conjugate directions \\(\\mathbb{\\delta}\\) are linearly independent, and thus for any scalar values \\(\\lambda_i\\), we can write, \\[\\begin{align} \\mathbb{x}^* &amp;= \\mathbb{x}_0 + \\lambda_1\\mathbb{\\delta}_1 + \\ldots + \\lambda_{n-1}\\mathbb{\\delta}_{n-1} \\nonumber \\\\ \\mathbb{x}^* - \\mathbb{x}_0 &amp;= \\lambda_1\\mathbb{\\delta}_1 + \\ldots + \\lambda_{n-1}\\mathbb{\\delta}_{n-1} \\tag{5.21} \\end{align}\\] Now, multiplying Eq. (5.21) non-commutatively by the preceding factor \\(\\mathbb{\\delta}_j^T\\mathbb{A}\\), and using the mutual conjugacy from Eq. (5.6), we will have, \\[\\begin{equation} \\mathbb{\\delta}_j^T\\mathbb{A}(\\mathbb{x}^*-\\mathbb{x}_0) = \\lambda_j\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j^T \\tag{5.22} \\end{equation}\\] which ultimately gives us, \\[\\begin{equation} \\lambda_j = \\frac{\\mathbb{\\delta}_j^T\\mathbb{A}(\\mathbb{x}^*-\\mathbb{x}_0)}{\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j^T} \\tag{5.23} \\end{equation}\\] Now again, using Eq. (5.14) we can generate the \\(j^{th}\\) iterate, given by, \\[\\begin{equation} \\mathbb{x}_j = x_0 + \\beta_1\\mathbb{\\delta}_1 + \\beta_2\\mathbb{\\delta}_2 + \\ldots + \\beta_{j-1}\\mathbb{\\delta}_{j-1} \\tag{5.24} \\end{equation}\\] Now subtracting Eq. (5.24) from the solution \\(\\mathbb{x}^*\\), we get, \\[\\begin{equation} \\mathbb{x}^* - \\mathbb{x}_j = \\mathbb{x}^* - \\mathbb{x}_0 - \\beta_1\\mathbb{\\delta}_1 - \\ldots - \\beta_{j-1}\\mathbb{\\delta}_{j-1} \\tag{5.25} \\end{equation}\\] fetching us, \\[\\begin{equation} \\mathbb{x}^* - \\mathbb{x}_0 = \\mathbb{x}^* - \\mathbb{x}_j + \\beta_1\\mathbb{\\delta}_1 - \\ldots + \\beta_{j-1}\\mathbb{\\delta}_{j-1} \\tag{5.26} \\end{equation}\\] Now, again multiplying Eq. (5.26) non-commutatively by the preceding factor \\(\\mathbb{\\delta}_j^T\\mathbb{A}\\), and using the mutual conjugacy from Eq. (5.6), we will have, \\[\\begin{equation} \\mathbb{\\delta}_j^T\\mathbb{A}(\\mathbb{x}^* - \\mathbb{x}_0) = \\mathbb{\\delta}_j^T\\mathbb{A}(\\mathbb{x}^* - \\mathbb{x}_j) \\tag{5.27} \\end{equation}\\] Using the fact that \\(\\mathbb{A}\\mathbb{x}^*=\\mathbb{b}\\) and also Eq. (5.18), we can modify Eq. (5.27) in the following way: \\[\\begin{align} \\mathbb{\\delta}_j^T\\mathbb{A}(\\mathbb{x}^* - \\mathbb{x}_0) &amp;= \\mathbb{\\delta}_j^T(\\mathbb{b} - \\mathbb{x}_j) \\nonumber \\\\ &amp;= -\\mathbb{\\delta}_j^T\\mathbb{r}_j \\nonumber \\\\ &amp;= -\\mathbb{r}_j^T\\mathbb{\\delta}_j \\tag{5.28} \\end{align}\\] So, Eq. (5.23) becomes, \\[\\begin{equation} \\lambda_j = -\\frac{\\mathbb{r}_j^T\\mathbb{\\delta}_j}{\\mathbb{\\delta}_j^T\\mathbb{A}\\mathbb{\\delta}_j} \\tag{5.29} \\end{equation}\\] which is similar to Eq. (5.20). So it can be concluded that, \\[\\begin{equation} \\lambda_j = \\beta_j \\tag{5.30} \\end{equation}\\] This completes the proof of the theorem. Theorem 5.4 The residual at the \\(j^{th}\\) iterate can be generated from the residual at the preceding iterate by the following iteration formula: \\[\\begin{equation} \\mathbb{r}_{j} = \\mathbb{r}_{j-1} + \\beta_j\\mathbb{A}\\mathbb{\\delta}_j \\tag{5.31} \\end{equation}\\] Proof. Substituting Eq. (5.14) in Eq. (5.4), we get, \\[\\begin{align} \\mathbb{r}_j &amp;= \\mathbb{A}(\\mathbb(x)_{j-1} + \\beta_j\\mathbb{\\delta}_j) - \\mathbb{b} \\nonumber \\\\ &amp;= \\mathbb{A}\\mathbb{x}_{j-1} + \\beta_j\\mathbb{A}\\mathbb{\\delta}_j - b \\nonumber \\\\ &amp;= (\\mathbb{A}\\mathbb{x}_{j-1} - b) + \\beta_j\\mathbb{A}\\mathbb{\\delta}_j \\nonumber \\\\ &amp;= \\mathbb{r}_{j-1} + \\beta_j\\mathbb{A}\\mathbb{\\delta}_j \\tag{5.32} \\end{align}\\] This completes the proof. 5.2.3 Preliminary Algorithm In the linear conjugate gradient method, the direction \\(\\mathbb{\\delta}_j\\) ix a linear combination of the preceding direction \\(\\mathbb{\\delta}_{j-1}\\) and the negative of the residual \\(-\\mathbb{r}_j\\). So we can write, \\[\\begin{equation} \\mathbb{\\delta}_j = \\chi_j \\mathbb{\\delta}_{j-1} - \\mathbb{r}_j \\tag{5.33} \\end{equation}\\] Now, to evaluate \\(\\chi_j\\), we multiply Eq. (5.33) non-commutatively with the preceding factor \\(\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\) and use the mutual conjugacy condition that \\(\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_j=0\\). \\[\\begin{equation} \\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_j = \\chi_j\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_{j-1} - \\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{r}_j = 0 \\tag{5.34} \\end{equation}\\] So, we see that, \\[\\begin{align} \\chi_j &amp;= \\frac{\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{r}_j}{\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_{j-1}} \\nonumber \\\\ &amp;= \\frac{(\\mathbb{A}\\mathbb{r}_j)^T\\mathbb{\\delta}_{j-1}}{\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_{j-1}} \\nonumber \\\\ &amp;= \\frac{\\mathbb{r}_j^T\\mathbb{A}^T\\mathbb{\\delta}_{j-1}}{\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_{j-1}} \\nonumber \\\\ &amp;= \\frac{\\mathbb{r}_j^T\\mathbb{A}\\mathbb{\\delta}_{j-1}}{\\mathbb{\\delta}_{j-1}^T\\mathbb{A}\\mathbb{\\delta}_{j-1}} \\tag{5.35} \\end{align}\\] The linear conjugate gradient algorithm is given below: Example 5.1 Let us consider an objective function given by: \\[\\begin{equation} f(x_1, x_2) = \\frac{x_1^2}{2} + x_1x_2 + x_2^2-2x_2 \\tag{5.36} \\end{equation}\\] Finding the minimizer of this objective function is equivalent to finding the solution to the equation given by \\(\\mathbb{A}\\mathbb{x} = \\mathbb{b}\\), where \\(\\mathbb{A} = \\begin{bmatrix} \\frac{1}{2} &amp; \\frac{1}{2} \\\\ \\frac{1}{2} &amp; 1\\end{bmatrix}\\), \\(\\mathbb{x} = \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}\\) and \\(\\mathbb{b} = \\begin{bmatrix}0 \\\\2\\end{bmatrix}\\). So, we use the linear conjugate gradient algorithm to solve \\[\\begin{equation} \\begin{bmatrix} \\frac{1}{2} &amp; \\frac{1}{2} \\\\ \\frac{1}{2} &amp; 1\\end{bmatrix} \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} = \\begin{bmatrix}0 \\\\2\\end{bmatrix} \\tag{5.37} \\end{equation}\\] where, we will consider the starting iterate to be \\(\\begin{bmatrix}-2.3 \\\\ 2.2 \\end{bmatrix}\\) tolerance \\(\\epsilon =10^{-5}\\). As usual, let us first define the objective function in Python. def f(x): # Define the objective function return x[0]**2/2 + x[0]*x[1] + x[1]**2 - 2*x[1] Next we define the matrix \\(\\mathbb{A}\\) and the vector \\(\\mathbb{b}\\) in Python. A = np.array(([1/2, 1/2], [1/2, 1]), dtype=float) b = np.array([0., 2.]) We can make it sure that \\(\\mathbb{A}\\) is actually a symmetric positive definite matrix. eigs = np.linalg.eigvals(A) print(&quot;The eigenvalues of A:&quot;, eigs) ## The eigenvalues of A: [0.19098301 1.30901699] if (np.all(eigs&gt;0)): print(&quot;A is positive definite&quot;) elif (np.all(eigs&gt;=0)): print(&quot;A is positive semi-definite&quot;) else: print(&quot;A is negative definite&quot;) ## A is positive definite We see that \\(\\mathbb{A}\\) is indeed positive definite. To check whether it is symmetric, we can check whether \\(\\mathbb{A}^T\\) equals \\(\\mathbb{A}\\). if (A.T==A).all()==True: print(&quot;A is symmetric&quot;) ## A is symmetric So \\(\\mathbb{A}\\) is symmetric too. Now we write the Python function linear_CG() that implements the linear conjugate gradient algorithm def linear_CG(x, A, b, epsilon): res = A.dot(x) - b # Initialize the residual delta = -res # Initialize the descent direction while True: if np.linalg.norm(res) &lt;= epsilon: return x, f(x) # Return the minimizer x* and the function value f(x*) D = A.dot(delta) beta = -(res.dot(delta))/(delta.dot(D)) # Line (11) in the algorithm x = x + beta*delta # Generate the new iterate res = A.dot(x) - b # generate the new residual chi = res.dot(D)/(delta.dot(D)) # Line (14) in the algorithm delta = chi*delta - res # Generate the new descent direction Finally, we pass the parameters that we consider for this example to the function linear_CG(). linear_CG(np.array([2.3, -2.2]), A, b, 10**-5) ## (array([-4., 4.]), 0.0) We see that the solution is \\(\\mathbb{x^*} \\sim \\begin{bmatrix}-4 \\\\ 4 \\end{bmatrix}\\) and the function value at this point is \\(0\\). We can verify the result is correct by following the trivial solution of Eq. (5.37): \\[\\begin{align} \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} &amp;= \\begin{bmatrix} \\frac{1}{2} &amp; \\frac{1}{2} \\\\ \\frac{1}{2} &amp; 1\\end{bmatrix}^{-1} \\begin{bmatrix}0 \\\\2\\end{bmatrix} \\nonumber \\\\ &amp;= \\begin{bmatrix}-4 \\\\ 4\\end{bmatrix} \\tag{5.38} \\end{align}\\] We can even write a Python code to check the above case: np.linalg.inv(A).dot(b) ## array([-4., 4.]) We see that our Python implementation of the linear conjugate gradient algorithm works perfectly. We will now discuss nonlinear conjugate gradient algorithms in the next section 5.3 Nonlinear Conjugate Gradient Algorithm We can modify our conjugate gradient method to optimize convex nonlinear objective functions. The first method that we study under this class is the Fletcher-Reeves method. 5.3.1 Feltcher-Reeves Algorithm The first application of the Conjugate Gradient Method on nonlinear objective functions was introduced by Fletcher and Reeves. The directions \\(\\mathbb{\\delta}_j\\) given by Fletcher and Reeves are mutually conjugate with respect to the symmetric positive definite matrix \\(\\mathbb{A}\\) in Eq. (5.1), where the residual is given by Eq. (5.5). The descent direction is given by, \\[\\begin{equation} \\mathbb{\\delta}_{j+1} = \\begin{cases} -\\nabla f(\\mathbb{x}_j),\\ \\ j=0 \\\\ -\\nabla f(\\mathbb{x}_j) + \\chi_j\\mathbb{\\delta}_j,\\ \\ j=1, 2, \\ldots, n-1 \\tag{5.39} \\end{cases} \\end{equation}\\] In the above equation, \\[\\begin{equation} \\mathbb{x}_j = \\mathbb{x}_{j-1}+\\beta_j\\mathbb{\\delta}_j \\tag{5.40} \\end{equation}\\] where \\(\\beta_j\\) is the \\(j^{th}\\) step length. \\(\\chi_j\\) in Eq. (5.39) is given by, \\[\\begin{equation} \\chi_j = \\frac{\\|\\nabla f(\\mathbb{x}_j)\\|^2}{\\|\\nabla f(\\mathbb{x}_{j-1})\\|^2} \\tag{5.41} \\end{equation}\\] The Fletcher-Reeves Algorithm is given below: Example 5.2 Let us consider an objective function having the form, \\[\\begin{equation} f(x_1, x_2) = x_1^4 - 2x_1^2x_2+x_1^2 + x_2^2-2x_1+1 \\tag{5.42} \\end{equation}\\] The function has a local minimizer at \\(f(1, 1) = 0\\). We will implement the Fletcher-Reeves algorithm in Python to figure out the minimizer. Let the starting iterate be given by \\(\\mathbb{x}_j = \\begin{bmatrix}2 \\\\ -1.8 \\end{bmatrix}\\), the tolerance be \\(\\epsilon = 10^{-5}\\) and the constants to be used for determining the step length using the be \\(\\alpha_1=10^{-4}\\) and \\(\\alpha_2=0.38\\). Let us first define the objective function and its gradient in Python. def func(x): # Objective function return x[0]**4 - 2*x[0]**2*x[1] + x[0]**2 + x[1]**2 - 2*x[0] + 1 Df = grad(func) # Gradient of the objective function Next we define the function Fletcher_Reeves() in Python: from scipy.optimize import line_search NORM = np.linalg.norm def Fletcher_Reeves(Xj, tol, alpha_1, alpha_2): x1 = [Xj[0]] x2 = [Xj[1]] D = Df(Xj) delta = -D # Initialize the descent direction while True: start_point = Xj # Start point for step length selection beta = line_search(f=func, myfprime=Df, xk=start_point, pk=delta, c1=alpha_1, c2=alpha_2)[0] # Selecting the step length if beta!=None: X = Xj+ beta*delta #Newly updated experimental point if NORM(Df(X)) &lt; tol: x1 += [X[0], ] x2 += [X[1], ] return X, func(X) # Return the results else: Xj = X d = D # Gradient at the preceding experimental point D = Df(Xj) # Gradient at the current experimental point chi = NORM(D)**2/NORM(d)**2 # Line (16) of the Fletcher-Reeves algorithm delta = -D + chi*delta # Newly updated descent direction x1 += [Xj[0], ] x2 += [Xj[1], ] According to our example we set our parameter values and pass them to the Fletcher_Reeves() function: Fletcher_Reeves(np.array([2., -1.8]), 10**-5, 10**-4, 0.38) ## (array([0.99999267, 0.99998207]), 6.445799449750211e-11) We notice that, for our choice of parameters, the algorithm has converged to the minimizer \\(\\mathbb{x}^* \\sim \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) with \\(f(\\mathbb{x}^*) \\sim 0\\). This Chapter is under construction "]]
