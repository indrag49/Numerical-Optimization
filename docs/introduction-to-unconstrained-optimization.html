<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Introduction to Unconstrained Optimization | Introduction to Mathematical Optimization</title>
  <meta name="description" content="A book for teaching introductory numerical optimization algorithms with Python" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Introduction to Unconstrained Optimization | Introduction to Mathematical Optimization" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://indrag49.github.io/Numerical-Optimization/" />
  
  <meta property="og:description" content="A book for teaching introductory numerical optimization algorithms with Python" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Introduction to Unconstrained Optimization | Introduction to Mathematical Optimization" />
  
  <meta name="twitter:description" content="A book for teaching introductory numerical optimization algorithms with Python" />
  

<meta name="author" content="Indranil Ghosh" />


<meta name="date" content="2021-06-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="solving-one-dimensional-optimization-problems.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mathematical Optimization</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What is Numerical Optimization?</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#introduction-to-optimization"><i class="fa fa-check"></i><b>1.1</b> Introduction to Optimization</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#a-solution"><i class="fa fa-check"></i><b>1.2</b> A Solution</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#maximization"><i class="fa fa-check"></i><b>1.3</b> Maximization</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#feasible-region"><i class="fa fa-check"></i><b>1.4</b> Feasible Region</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#discrete-optimization-problems"><i class="fa fa-check"></i><b>1.5</b> Discrete Optimization Problems</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#linear-programming-problems"><i class="fa fa-check"></i><b>1.6</b> Linear Programming Problems</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#stochastic-optimization-problems"><i class="fa fa-check"></i><b>1.7</b> Stochastic Optimization Problems</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#scaling-of-decision-variables"><i class="fa fa-check"></i><b>1.8</b> Scaling of Decision Variables</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#gradient-vector-and-hessian-matrix-of-the-objective-function"><i class="fa fa-check"></i><b>1.9</b> Gradient Vector and Hessian Matrix of the Objective Function</a></li>
<li class="chapter" data-level="1.10" data-path="index.html"><a href="index.html#directional-derivative-of-the-objective-function"><i class="fa fa-check"></i><b>1.10</b> Directional Derivative of the Objective Function</a></li>
<li class="chapter" data-level="1.11" data-path="index.html"><a href="index.html#positive-definite-and-positive-semi-definite-matrices"><i class="fa fa-check"></i><b>1.11</b> Positive Definite and Positive Semi-definite Matrices</a></li>
<li class="chapter" data-level="1.12" data-path="index.html"><a href="index.html#what-is-convexity"><i class="fa fa-check"></i><b>1.12</b> What is Convexity?</a></li>
<li class="chapter" data-level="1.13" data-path="index.html"><a href="index.html#numerical-optimization-algorithms"><i class="fa fa-check"></i><b>1.13</b> Numerical Optimization Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html"><i class="fa fa-check"></i><b>2</b> Introduction to Unconstrained Optimization</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#the-unconstrained-optimization-problem"><i class="fa fa-check"></i><b>2.1</b> The Unconstrained Optimization Problem</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#smooth-functions"><i class="fa fa-check"></i><b>2.2</b> Smooth Functions</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#taylors-theorem"><i class="fa fa-check"></i><b>2.3</b> Taylor’s Theorem</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#necessary-and-sufficient-conditions-for-local-minimizer-in-unconstrained-optimization"><i class="fa fa-check"></i><b>2.4</b> Necessary and Sufficient Conditions for Local Minimizer in Unconstrained Optimization</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#first-order-necessary-condition"><i class="fa fa-check"></i><b>2.4.1</b> First-Order Necessary Condition</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#second-order-necessary-conditions"><i class="fa fa-check"></i><b>2.4.2</b> Second-Order Necessary Conditions</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#second-order-sufficient-conditions"><i class="fa fa-check"></i><b>2.4.3</b> Second-Order Sufficient Conditions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-unconstrained-optimization.html"><a href="introduction-to-unconstrained-optimization.html#algorithms-for-solving-unconstrained-minimization-tasks"><i class="fa fa-check"></i><b>2.5</b> Algorithms for Solving Unconstrained Minimization Tasks</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html"><i class="fa fa-check"></i><b>3</b> Solving One Dimensional Optimization Problems</a><ul>
<li class="chapter" data-level="3.1" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#one-dimensional-optimization-problems"><i class="fa fa-check"></i><b>3.1</b> One Dimensional Optimization Problems</a></li>
<li class="chapter" data-level="3.2" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#what-is-a-unimodal-function"><i class="fa fa-check"></i><b>3.2</b> What is a Unimodal Function?</a></li>
<li class="chapter" data-level="3.3" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#fibonacci-search-method"><i class="fa fa-check"></i><b>3.3</b> Fibonacci Search Method</a></li>
<li class="chapter" data-level="3.4" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#golden-section-search-method"><i class="fa fa-check"></i><b>3.4</b> Golden Section Search Method</a></li>
<li class="chapter" data-level="3.5" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#powells-quadratic-interpolation-method"><i class="fa fa-check"></i><b>3.5</b> Powell’s Quadratic Interpolation Method</a></li>
<li class="chapter" data-level="3.6" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#inverse-quadratic-interpolation-method"><i class="fa fa-check"></i><b>3.6</b> Inverse Quadratic Interpolation Method</a></li>
<li class="chapter" data-level="3.7" data-path="solving-one-dimensional-optimization-problems.html"><a href="solving-one-dimensional-optimization-problems.html#newtons-method"><i class="fa fa-check"></i><b>3.7</b> Newton’s Method</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Mathematical Optimization</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-unconstrained-optimization" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Introduction to Unconstrained Optimization</h1>
<p>This chapter introduces what exactly an unconstrained optimization problem is. A detailed discussion of Taylor’s Theorem is provided and has been use to study the first order and second order necessary and sufficient conditions for local minimizer in an unconstrained optimization tasks. Examples have been supplied too in view of understanding the necessary and sufficient conditions better. The Python package <code>scipy.optimize</code>, which will form an integral part in solving many optimization problems in the later chapters of this book, is introduced too. The chapter ends with an overview of how an algorithm to solve unconstrained minimization problem works, covering briefly two procedures: <strong>line search descent method</strong> and <strong>trust region method</strong>.</p>
<hr />
<div id="the-unconstrained-optimization-problem" class="section level2">
<h2><span class="header-section-number">2.1</span> The Unconstrained Optimization Problem</h2>
<p>As we have discussed in the first chapter, an unconstrained optimization problem deals with finding the local minimizer <span class="math inline">\(\mathbf{x}^*\)</span> of a real valued and smooth objective function <span class="math inline">\(f(\mathbf{x})\)</span> of <span class="math inline">\(n\)</span> variables, given by <span class="math inline">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, formulated as,</p>
<p><span class="math display" id="eq:1">\[\begin{equation}
    \underset{\mathbf{x} \in \mathbb{R}^n}{\min f(\mathbf{x})} \tag{2.1}
\end{equation}\]</span>
with no restrictions on the decision variables <span class="math inline">\(\mathbf{x}\)</span>. We work towards computing <span class="math inline">\(\mathbf{x}^*\)</span>, such that <span class="math inline">\(\forall\ \mathbf{x}\)</span> near <span class="math inline">\(\mathbf{x}^*\)</span>, the following inequality is satisfied:
<span class="math display" id="eq:2">\[\begin{equation}
    f(\mathbf{x}^*) \leq f(\mathbf{x}) \tag{2.2}
\end{equation}\]</span></p>
</div>
<div id="smooth-functions" class="section level2">
<h2><span class="header-section-number">2.2</span> Smooth Functions</h2>
<p>In terms of analysis, the measure of the number of continuous derivative a function has, characterizes the <em>smoothness</em> of a function.</p>

<div class="definition">
<span id="def:unnamed-chunk-1" class="definition"><strong>Definition 2.1  </strong></span>A function <span class="math inline">\(f\)</span> is <em>smooth</em> if it can be differentiated everywhere, i.e, the function has continuous derivatives up to some desired order over particular domain [Weisstein, Eric W. “Smooth Function.” <a href="https://mathworld.wolfram.com/SmoothFunction.html" class="uri">https://mathworld.wolfram.com/SmoothFunction.html</a>].
</div>

<p>Some examples of smooth functions are , <span class="math inline">\(f(x) = x\)</span>, <span class="math inline">\(f(x)=e^x\)</span>, <span class="math inline">\(f(x)=\sin(x)\)</span>, etc. To study the local minima <span class="math inline">\(\mathbf{x}^*\)</span> of a smooth objective function <span class="math inline">\(f(\mathbf{x})\)</span>, we emphasize on <em>Taylor’s theorem for a multivariate function</em>, thus focusing on the computations of the gradient vector <span class="math inline">\(\nabla f(\mathbf{x})\)</span> and the Hessian matrix <span class="math inline">\(\mathbf{H} f(\mathbf{x})\)</span>.</p>
</div>
<div id="taylors-theorem" class="section level2">
<h2><span class="header-section-number">2.3</span> Taylor’s Theorem</h2>

<div class="theorem">
<span id="thm:unnamed-chunk-2" class="theorem"><strong>Theorem 2.1  </strong></span>For a smooth function of a single variable given by <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math inline">\(m(\geq 1)\)</span> times differentiable at the point <span class="math inline">\(p \in \mathbb{R}\)</span>, there exists a function <span class="math inline">\(j_m: \mathbb{R} \rightarrow \mathbb{R}\)</span>, such that the following equations are satisfied:
<span class="math display" id="eq:3">\[\begin{align}
    f(x) &amp;= f(p) + (x - p)f^{&#39;}(p) + \frac{(x-p)^2}{2!}f^{&#39;&#39;}(p) + \ldots \\ &amp;+ \frac{(x-p)^m}{m!}f^m(p) + (x-p)^m j_m(x) \tag{2.3}
\end{align}\]</span>
and
<span class="math display" id="eq:4">\[\begin{equation}
    \lim_{x \to p}j_m(x)=0 \tag{2.4}
\end{equation}\]</span>
</div>

<p>The <span class="math inline">\(m-\)</span>th order Taylor polynomial of the function <span class="math inline">\(f\)</span> around the point <span class="math inline">\(p\)</span> is given by:
<span class="math display" id="eq:5">\[\begin{align}
    P_m(x)&amp;=f(p) + (x - p)f^{&#39;}(p) + \frac{(x-p)^2}{2!}f^{&#39;&#39;}(p) + \ldots \\ &amp;+ \frac{(x-p)^m}{m!}f^m(p) \tag{2.5}
\end{align}\]</span></p>
<p>Now let <span class="math inline">\(f\)</span> be a smooth, continuously differentiable function that takes in multiple variables, i.e, <span class="math inline">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(\mathbf{x}, \mathbf{p}, \mathbf{\delta} \in \mathbb{R}^n\)</span>, where <span class="math inline">\(\mathbf{\delta}\)</span> is the direction in which the line <span class="math inline">\(\mathbf{x} = \mathbf{p}+\alpha \mathbf{\delta}\)</span> passes through the point <span class="math inline">\(\mathbf{p}\)</span> [<em>Snyman, Jan A. Practical mathematical optimization. Springer Science+ Business Media, Incorporated, 2005.</em>]. Here, <span class="math inline">\(\alpha \in [0,1]\)</span>. We have,
<span class="math display" id="eq:6">\[\begin{equation}
    f(\mathbf{x}) = f(\mathbf{p} + \alpha \mathbf{\delta}) \tag{2.6}
\end{equation}\]</span></p>
<p>From the definition of the <em>directional derivative</em>, we get,
<span class="math display" id="eq:7">\[\begin{equation}
    \frac{df(\mathbf{x})}{d\alpha}|\mathbf{\delta} = \nabla^T f(\mathbf{x})\mathbf{\delta}=\hat{f}(\mathbf{x}) \tag{2.7}
\end{equation}\]</span>
Again, differentiating <span class="math inline">\(\hat{f}(\mathbf{x})\)</span> with respect to <span class="math inline">\(\alpha\)</span>.</p>
<p><span class="math display" id="eq:8">\[\begin{equation}
    \frac{d \hat{f}(\mathbf{x})}{d \alpha}|\mathbf{\delta} = \frac{d^2 f(\mathbf{x})}{d \alpha^2}=\nabla^T\hat{f}(\mathbf{x})\mathbf{\delta}=\mathbf{\delta}^T\mathbf{H}f(\mathbf{x})\mathbf{\delta} \tag{2.8}
\end{equation}\]</span></p>
<p>So, using equations <a href="introduction-to-unconstrained-optimization.html#eq:5">(2.5)</a> and <a href="introduction-to-unconstrained-optimization.html#eq:6">(2.6)</a> we can generate the Taylor expansion for a multivariable function at a point <span class="math inline">\(\mathbf{p}\)</span>. So, around <span class="math inline">\(\alpha = 0\)</span>, we get,
<span class="math display" id="eq:9">\[\begin{equation}
    f(\mathbf{x}) = f(\mathbf{p}+\alpha \mathbf{\delta}) = f(\mathbf{p}) + \nabla^Tf(\mathbf{p})\alpha \mathbf{\delta} + \frac{1}{2}\alpha \mathbf{\delta}^T\mathbf{H} f(\mathbf{p})\alpha \mathbf{\delta} + \ldots \tag{2.9}
\end{equation}\]</span></p>
<p>The truncated Taylor expansion of the multivariable function, where the higher order terms are ignored, can be written as,
<span class="math display" id="eq:10">\[\begin{equation}
    f(\mathbf{x}) = f(\mathbf{p}+\alpha \mathbf{\delta}) = f(\mathbf{p}) + \nabla^Tf(\mathbf{p})\alpha \mathbf{\delta} + \frac{1}{2}\alpha \mathbf{\delta}^T\mathbf{H} f(\mathbf{p}+\beta\mathbf{\delta})\alpha \mathbf{\delta} \tag{2.10} 
\end{equation}\]</span>
where, <span class="math inline">\(\beta \in [0,1]\)</span>.</p>
</div>
<div id="necessary-and-sufficient-conditions-for-local-minimizer-in-unconstrained-optimization" class="section level2">
<h2><span class="header-section-number">2.4</span> Necessary and Sufficient Conditions for Local Minimizer in Unconstrained Optimization</h2>
<div id="first-order-necessary-condition" class="section level3">
<h3><span class="header-section-number">2.4.1</span> First-Order Necessary Condition</h3>
<p>If there exists a local minimizer <span class="math inline">\(\mathbf{x}^*\)</span> for a real-valued smooth function <span class="math inline">\(f(\mathbf{x}): \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, in an open neighborhood <span class="math inline">\(\subset \mathbb{R}^n\)</span> of <span class="math inline">\(\mathbf{x}^*\)</span> along the direction <span class="math inline">\(\mathbf{\delta}\)</span>, then the <em>first order necessary condition</em> for the minimizer is given by:
<span class="math display" id="eq:11">\[\begin{equation}
    \nabla^Tf(\mathbf{x}^*)\mathbf{\delta}=0\ \forall\ \mathbf{\delta} \neq 0 \tag{2.11}
\end{equation}\]</span>
i.e, the <em>directional derivative</em> is <span class="math inline">\(0\)</span>, which ultimately reduces to the equation:
<span class="math display" id="eq:12">\[\begin{equation}
    \nabla f(\mathbf{x}^*)=0 \tag{2.12}
\end{equation}\]</span></p>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Let a real-valued smooth function <span class="math inline">\(f(\mathbf{x})\)</span> be differentiable at the point <span class="math inline">\(\mathbf{x}^* \in \mathbb{R}^n\)</span>. Using the <em>Taylor expansion</em>, we can write:</p>
<p><span class="math display" id="eq:13">\[\begin{equation}
    f(\mathbf{x})=f(\mathbf{x}^*) + \nabla^T f(\mathbf{x}^*) (\mathbf{x} - \mathbf{x}^*)+\sum_{|\gamma|\leq m}\frac{\mathfrak{D}^{\gamma}f(\mathbf{x}^*)}{\gamma!}(\mathbf{x}-\mathbf{x}^*)^{\gamma} + \sum_{|\gamma|=m}j_{\gamma}(\mathbf{x})(\mathbf{x} - \mathbf{x}^*)^{\gamma} \tag{2.13}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathfrak{D}\)</span> represents the differential and <span class="math inline">\(m\)</span> is the smoothness of the objective function <span class="math inline">\(f\)</span>. Also <span class="math inline">\(\lim_{\mathbf{x} \to \mathbf{x}^*}j_{\gamma(\mathbf{X})}=0\)</span>. Clubbing together the higher order terms, we can write Eq.<a href="introduction-to-unconstrained-optimization.html#eq:13">(2.13)</a> as,
<span class="math display" id="eq:14">\[\begin{equation}
    \label{eq:2.14}
    f(\mathbf{x})=f(\mathbf{x}^*) + \nabla^T f(\mathbf{x}^*) (\mathbf{x} - \mathbf{x}^*)+ \mathcal{O}(\|\mathbf{x} - \mathbf{x}^*\|) \tag{2.14}
\end{equation}\]</span></p>
<p>In this case,
<span class="math display" id="eq:15">\[\begin{equation}
\lim_{\mathbf{x} \to \mathbf{x}^*}\frac{\mathcal{O}(\|\mathbf{x} - \mathbf{x}^*\|)}{\|\mathbf{x} - \mathbf{x}^*\|}=0 \tag{2.15}
\end{equation}\]</span>
Let us consider, <span class="math inline">\(\mathbf{x} = \mathbf{x}^*-\beta \nabla f(\mathbf{x}^*)\)</span>, where <span class="math inline">\(\beta \in [0,1]\)</span>. From Eq.<a href="introduction-to-unconstrained-optimization.html#eq:14">(2.14)</a> we can write,
<span class="math display" id="eq:16">\[\begin{equation}
    f(\mathbf{x}^*-\beta \nabla f(\mathbf{x}^*))=f(\mathbf{x}^*)-\beta\|\nabla f(\mathbf{x}^*)\|^2+\mathcal{O}(\beta\|\nabla f(\mathbf{x}^*)\|) \tag{2.16}
\end{equation}\]</span></p>
<p>Now, dividing Eq.<a href="introduction-to-unconstrained-optimization.html#eq:16">(2.16)</a>-<span class="math inline">\(f(\mathbf{x}^*)\)</span> by <span class="math inline">\(\beta\)</span>, we get,</p>
<p><span class="math display" id="eq:17">\[\begin{equation}
    \frac{f(\mathbf{x}^*-\beta \nabla f(\mathbf{x}^*))-f(\mathbf{x}^*)}{\beta} = -\|\nabla f(\mathbf{x}^*)\|^2 + \frac{\mathcal{O}(\beta \|\nabla f(\mathbf{x}^*)\|)}{\beta} \geq 0 \tag{2.17}
\end{equation}\]</span></p>
<p>Now, considering the limit <span class="math inline">\(\beta \to 0^{+}\)</span>, we get,
<span class="math display" id="eq:18">\[\begin{equation}
    -\|\nabla f(\mathbf{x}^*)\|^2 \leq 0 \tag{2.18}
\end{equation}\]</span></p>
Combining which along with Eq.<a href="introduction-to-unconstrained-optimization.html#eq:18">(2.18)</a>, we get,
<span class="math display" id="eq:19">\[\begin{equation}
    0 \leq -\|\nabla f(\mathbf{x}^*)\|^2 \leq 0\tag{2.19}
\end{equation}\]</span>
This ultimately gives <span class="math inline">\(\nabla f(\mathbf{x}^*)=0\)</span>, proving the first-order necessary condition.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-4" class="example"><strong>Example 2.1  </strong></span>The <strong>Rosenbrock function</strong> of <span class="math inline">\(n\)</span>-variables is given by:
<span class="math display" id="eq:20">\[\begin{equation}
    f(\mathbf{x}) = \sum_{i=1}^{n-1}(100(x_{i+1}-x_i^2)^2 + (1-x_i)^2) \tag{2.20}
\end{equation}\]</span></p>
<p>where, <span class="math inline">\(\mathbf{x} \in \mathbb{R}^n\)</span>. For this example let us consider the <em>Rosenbrock function</em> for two variables, given by:
<span class="math display" id="eq:21">\[\begin{equation}
    f(\mathbf{x}) = 100(x_2-x_1^2)^2+(1-x_1)^2 \tag{2.21}
\end{equation}\]</span></p>
<p>We will show that the first order necessary condition is satisfied for the local minimizer <span class="math inline">\(\mathbf{x^*}=\begin{bmatrix} 1 \\ 1 \end{bmatrix}\)</span>. We first check whether <span class="math inline">\(\mathbf{x}^*\)</span> is a minimizer or not. Putting <span class="math inline">\(x_1=x_2=1\)</span> in <span class="math inline">\(f(\mathbf{x})\)</span>, we get <span class="math inline">\(f(\mathbf{x})=0\)</span>. Now, we check whether the <span class="math inline">\(\mathbf{x^*}\)</span> satisfies the first order necessary condition. For that we calculate <span class="math inline">\(\nabla f(\mathbf{x}^*)\)</span>.
<span class="math display" id="eq:22">\[\begin{equation}
    \nabla f(\mathbf{x}^*) = \begin{bmatrix} -400x_1(x_2-x_1)^2-2(1-x_1) \\ 200(x_2-x_1^2)\end{bmatrix}_{\mathbf{x}^*} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} \tag{2.22}
\end{equation}\]</span></p>
<p>So, we see that the first order necessary condition is satisfied. We can do similar analysis using the <code>scipy.optimize</code> package in Python. The Scipy official reference states that the <code>scipy.optimize</code> package provides the user with many commonly used optimization algorithms and test functions. It packages the following functionalities and aspects:</p>
<ul>
<li>Minimization of multivariate scalar objective functions covering both the unconstrained and constrained domains, using a range of optimization algorithms,</li>
<li>Algorithms for minimization of scalar univariate functions,</li>
<li>A variety of brute-force optimization algorithms, also called global optimization algorithms,</li>
<li>Algorithms like minimization of least-squares and curve-fitting,</li>
<li>Root finding algorithms, and</li>
<li>Algorithms for solving multivariate equation systems.</li>
</ul>
We will build upon the basic concepts of optimization using this package and cover most of the concepts one by one as we advance in the book. Note that, this is not the only package that we are going to use throughout the book. As we advance, we will be required to look into other Python resources according to our needs. But to keep in mind, <code>scipy.optimize</code> is the most important package that we will be using. Now, going back to the example, <code>scipy.optimize</code> already provides with the  test function, its gradient and its Hessian. We will import them first and check whether the given point <span class="math inline">\(\mathbf{x}^*\)</span> is a minimizer or not:
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="introduction-to-unconstrained-optimization.html#cb1-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="introduction-to-unconstrained-optimization.html#cb1-2"></a><span class="im">import</span> scipy</span>
<span id="cb1-3"><a href="introduction-to-unconstrained-optimization.html#cb1-3"></a><span class="co"># Import the Rosenbrock function, its gradient and Hessian respectively</span></span>
<span id="cb1-4"><a href="introduction-to-unconstrained-optimization.html#cb1-4"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> rosen, rosen_der, rosen_hess</span>
<span id="cb1-5"><a href="introduction-to-unconstrained-optimization.html#cb1-5"></a>x_m <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">1</span>]) <span class="co">#given local minimizer</span></span>
<span id="cb1-6"><a href="introduction-to-unconstrained-optimization.html#cb1-6"></a>rosen(x_m) <span class="co"># check whether x_m is a minimizer</span></span></code></pre></div>
<pre><code>## 0.0</code></pre>
<p>the result is <span class="math inline">\(0.0\)</span>. So <span class="math inline">\(\mathbf{x}^*\)</span> is a minimizer. We then check for the first order necessary condition, using the gradient:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="introduction-to-unconstrained-optimization.html#cb3-1"></a>rosen_der(x_m) <span class="co"># calculates the gradient at the point x_m</span></span></code></pre></div>
<pre><code>## array([0, 0])</code></pre>
<p>This matches with our calculations and also satisfies the first-order necessary condition.</p>
</div>
<div id="second-order-necessary-conditions" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Second-Order Necessary Conditions</h3>
<p>If there exists a local minimizer <span class="math inline">\(\mathbf{x}^*\)</span> for a real-valued smooth function <span class="math inline">\(f(\mathbf{x}): \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, in an open neighborhood <span class="math inline">\(\subset \mathbb{R}^n\)</span> of <span class="math inline">\(\mathbf{x}^*\)</span> along the feasible direction <span class="math inline">\(\mathbf{\delta}\)</span>, and <span class="math inline">\(\mathbf{H} f(\mathbf{x})\)</span> exists and is continuous in the open neighborhood, then the second order necessary conditions for the minimizer are given by:
<span class="math display" id="eq:23">\[\begin{equation}
    \nabla^T f(\mathbf{x}^*)\mathbf{\delta} = 0, \forall\ \mathbf{\delta} \neq 0 \tag{2.23}
\end{equation}\]</span>
and
<span class="math display" id="eq:24">\[\begin{equation}
    \mathbf{\delta}^T\mathbf{H}f(\mathbf{x}^*)\mathbf{\delta} \geq 0, \forall\ \mathbf{\delta} \neq 0 \tag{2.24}
\end{equation}\]</span>
which reduces to the following:
<span class="math display" id="eq:25">\[\begin{equation}
    \nabla f(\mathbf{x}^*) = 0 \tag{2.25}
\end{equation}\]</span>
and
<span class="math display" id="eq:26">\[\begin{equation}
    \mathbf{\delta}\mathbf{H}f(\mathbf{x}^*) \geq 0 \tag{2.26}
\end{equation}\]</span>
where equation Eq.<a href="introduction-to-unconstrained-optimization.html#eq:26">(2.26)</a> means that the Hessian matrix should be positive semi-definite.</p>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> From the proof of first order necessary condition, we know that <span class="math inline">\(\nabla f(\mathbf{x}^*) = 0\)</span>, which satisfies equation Eq.<a href="introduction-to-unconstrained-optimization.html#eq:25">(2.25)</a>. Now for proving equation Eq.<a href="introduction-to-unconstrained-optimization.html#eq:26">(2.26)</a>, we use the Taylor series expansion again. We have,
<span class="math display" id="eq:27">\[\begin{equation}
    f(\mathbf{x}) = f(\mathbf{x}^*)+\nabla^T f(\mathbf{x}^*)(\mathbf{x} - \mathbf{x}^*) + \frac{1}{2}\mathbf{H} f(\mathbf{x}^*)(\mathbf{x} - \mathbf{x}^*) + \mathcal{O}(\|\mathbf{x} - \mathbf{x}^*\|^2) \tag{2.27}
\end{equation}\]</span></p>
<p>Given, the feasible direction <span class="math inline">\(\mathbf{\delta}\)</span>, we take <span class="math inline">\(\beta \in [0,1]\)</span>, such that <span class="math inline">\(\mathbf{x} = \mathbf{x}^* + \beta \mathbf{\delta}\)</span>. Putting this in Eq.<a href="introduction-to-unconstrained-optimization.html#eq:27">(2.27)</a> and rearranging, we get,
<span class="math display" id="eq:28">\[\begin{equation}
    f(\mathbf{x}^* + \beta \mathbf{\delta}) - f(\mathbf{x}^*) = \beta \nabla^T f(\mathbf{x}^*)\mathbf{\delta} + \frac{\beta^2}{2}\mathbf{\delta}^T \mathbf{H} f(\mathbf{x}^*)\mathbf{\delta} + \mathcal{O}(\beta^2) \tag{2.28}
\end{equation}\]</span></p>
<p>As, <span class="math inline">\(\nabla f(\mathbf{x}^*)=0\)</span>, we have
<span class="math display" id="eq:29">\[\begin{equation}
    f(\mathbf{x}^* + \beta \mathbf{\delta}) - f(\mathbf{x}^*) = \frac{\beta^2}{2}\mathbf{\delta}^T \mathbf{H} f(\mathbf{x}^*)\mathbf{\delta} + \mathcal{O}(\beta^2) \tag{2.29}
\end{equation}\]</span></p>
<p>Now, dividing Eq.<a href="introduction-to-unconstrained-optimization.html#eq:29">(2.29)</a> by <span class="math inline">\(\beta^2\)</span>, we have,
<span class="math display" id="eq:30">\[\begin{equation}
    \frac{f(\mathbf{x}^* + \beta \mathbf{\delta}) - f(\mathbf{x}^*)}{\beta^2} = \frac{1}{2}\mathbf{\delta}^T \mathbf{H} f(\mathbf{x}^*)\mathbf{\delta} + \frac{\mathcal{O}(\beta^2)}{\beta^2} \geq 0 \tag{2.30}
\end{equation}\]</span></p>
Taking the limit <span class="math inline">\(\beta \to 0\)</span>, we have,
<span class="math display" id="eq:31">\[\begin{equation}
    \mathbf{\delta}^T \mathbf{H} f(\mathbf{x}^*) \mathbf{\delta} \geq 0 \tag{2.31}
\end{equation}\]</span>
Which ultimately reduces to,
<span class="math display" id="eq:32">\[\begin{equation}
    \mathbf{H} f(\mathbf{x}^*) \geq 0 \tag{2.32}
\end{equation}\]</span>
We see that the Hessian matrix is positive semi-definite. This completes the proof of the second order necessary conditions. [refer to chapter 1, optimality conditions]
</div>

</div>
<div id="second-order-sufficient-conditions" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Second-Order Sufficient Conditions</h3>
<p>For a real-valued smooth objective function <span class="math inline">\(f(\mathbf{x})\)</span>, if <span class="math inline">\(\mathbf{x}^*\)</span> is its local minimizer and <span class="math inline">\(\mathbf{H} f(\mathbf{x})\)</span> exists and is continuous in an open neighborhood <span class="math inline">\(\subset \mathbb{R}^n\)</span> of <span class="math inline">\(\mathbf{x}^*\)</span> along the feasible direction <span class="math inline">\(\mathbf{\delta}\)</span>, then the conditions:
<span class="math display" id="eq:33">\[\begin{equation}
    \nabla^T f(\mathbf{x}^*)\delta = 0 \tag{2.33}
\end{equation}\]</span>
i.e,
<span class="math display" id="eq:34">\[\begin{equation}
    \nabla f(\mathbf{x}^*) = 0 \tag{2.34}
\end{equation}\]</span>
and</p>
<p><span class="math display" id="eq:35">\[\begin{equation}
    \mathbf{\delta}^T \mathbf{H} f(\mathbf{x}^*) \mathbf{\delta} &gt; 0 \tag{2.35}
\end{equation}\]</span></p>
<p>i.e, a positive definite Hessian matrix imply that <span class="math inline">\(\mathbf{x}^*\)</span> is a strong local minimizer of <span class="math inline">\(f(\mathbf{x})\)</span>.</p>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Let <span class="math inline">\(\mathfrak{r} &gt;0\)</span> be a radius such that the Hessian of the objective function, <span class="math inline">\(\mathbf{H} f(\mathbf{x})\)</span> is positive definite <span class="math inline">\(\forall\ \mathbf{x}\)</span> in the open ball defined by <span class="math inline">\(\mathfrak{B} = \{\mathbf{y} \mid \|\mathbf{y} - \mathbf{x}^*\| \leq \mathfrak{r}\}\)</span>. This comes from the fact that <span class="math inline">\(\mathbf{H} f(\mathbf{x})\)</span> is positive definite at the local minimizer <span class="math inline">\(\mathbf{x}^*\)</span>. Now, considering a nonzero vector <span class="math inline">\(\mathbf{\eta}\)</span>, such that <span class="math inline">\(\|\mathbf{\eta}\| &lt; \mathfrak{r}\)</span> and <span class="math inline">\(c \in [0,1]\)</span>, we will have, <span class="math inline">\(\mathbf{x}=\mathbf{x}^*+c\mathbf{\eta} \in \mathfrak{B}\)</span>. Now, using the Taylor’s expansion, i.e, Eq.<a href="introduction-to-unconstrained-optimization.html#eq:27">(2.27)</a>, we will have,</p>
<p><span class="math display" id="eq:36">\[\begin{equation}
    f(\mathbf{x}^* + \mathbf{\eta}) = f(\mathbf{x}^*) + c\nabla^Tf(\mathbf{x}^*)\mathbf{\eta} + \frac{c^2}{2}\mathbf{\eta}^T\mathbf{H} f(\mathbf{y})\mathbf{\eta} + \mathcal{O}(c^2) \tag{2.36}
\end{equation}\]</span></p>
<p>Since, <span class="math inline">\(\nabla f(\mathbf{x}^*) = 0\)</span>, we have,
<span class="math display" id="eq:37">\[\begin{equation}
    \frac{f(\mathbf{x}^* + \mathbf{\eta}) - f(\mathbf{x}^*)}{c^2} = \frac{1}{2}\mathbf{\eta}^T\mathbf{H}f(\mathbf{y})\mathbf{\eta}+\frac{\mathcal{O}(c^2)}{c^2} \tag{2.37}
\end{equation}\]</span></p>
<p>Here, <span class="math inline">\(\mathbf{y} = \mathbf{x}^* + \beta \mathbf{\eta}\)</span> with <span class="math inline">\(\beta \in [0,1]\)</span>. As, <span class="math inline">\(\mathbf{y} \in \mathfrak{B}\)</span>, we have,
<span class="math display" id="eq:38">\[\begin{equation}
    \mathbf{\eta}^T\mathbf{H}f(\mathbf{y})\mathbf{\eta} &gt; 0 \tag{2.38}
\end{equation}\]</span></p>
<p>So, taking the limit, <span class="math inline">\(c \to 0\)</span>, we have,
<span class="math display" id="eq:39">\[\begin{equation}
    f(\mathbf{x}^* + \mathbf{\eta}) - f(\mathbf{x}^*) &gt; 0 \tag{2.39}
\end{equation}\]</span></p>
this proves our claim that,
<span class="math display" id="eq:40">\[\begin{equation}
    f(\mathbf{x}^* + \mathbf{\eta}) &gt; f(\mathbf{x}^*) \tag{2.40}
\end{equation}\]</span>
that is, <span class="math inline">\(\mathbf{x}^*\)</span> is a strict local minimizer of the objective function <span class="math inline">\(f(\mathbf{x})\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-9" class="example"><strong>Example 2.2  </strong></span>Let us now work with a new test function called Himmelblau’s function, given by,
<span class="math display" id="eq:41">\[\begin{equation}
    f(\mathbf{x}) = (x_1^2+x_2-11)^2+(x_1+x_2^2-7)^2 \tag{2.41}
\end{equation}\]</span></p>
where, <span class="math inline">\(\mathbf{x} \in \mathbb{R}^2\)</span>. We will check whether <span class="math inline">\(\mathbf{x}^*=\begin{bmatrix} 3 \\ 2 \end{bmatrix}\)</span> satisfies the second-order sufficient conditions satisfying the fact that it is a strong local minimizer. We will again use the <code>autograd</code> package to do the analyses for this objective function. Let us first define the function and the local minimizer as <code>x_star</code> in Python:
</div>

<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="introduction-to-unconstrained-optimization.html#cb5-1"></a><span class="kw">def</span> Himm(x):</span>
<span id="cb5-2"><a href="introduction-to-unconstrained-optimization.html#cb5-2"></a>    <span class="cf">return</span> (x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> x[<span class="dv">1</span>] <span class="op">-</span> <span class="dv">11</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> (x[<span class="dv">0</span>] <span class="op">+</span> x[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">7</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-3"><a href="introduction-to-unconstrained-optimization.html#cb5-3"></a></span>
<span id="cb5-4"><a href="introduction-to-unconstrained-optimization.html#cb5-4"></a>x_star <span class="op">=</span> np.array([<span class="dv">3</span>, <span class="dv">2</span>], dtype<span class="op">=</span><span class="st">&#39;float&#39;</span>) <span class="co">#local minimizer</span></span></code></pre></div>
<p>We then check whether <code>x_star</code> is a minimizer.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="introduction-to-unconstrained-optimization.html#cb6-1"></a><span class="bu">print</span>(<span class="st">&quot;function at x_star:&quot;</span>, Himm(x_star))</span></code></pre></div>
<pre><code>## function at x_star: 0.0</code></pre>
<p>Now, we calculate the gradient vector and the Hessian matrix of the function at <code>x_star</code> and look at the results,</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="introduction-to-unconstrained-optimization.html#cb8-1"></a><span class="co"># import the necessary packages</span></span>
<span id="cb8-2"><a href="introduction-to-unconstrained-optimization.html#cb8-2"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> au</span>
<span id="cb8-3"><a href="introduction-to-unconstrained-optimization.html#cb8-3"></a><span class="im">from</span> autograd <span class="im">import</span> grad, jacobian</span>
<span id="cb8-4"><a href="introduction-to-unconstrained-optimization.html#cb8-4"></a></span>
<span id="cb8-5"><a href="introduction-to-unconstrained-optimization.html#cb8-5"></a><span class="co"># gradient vector of the Himmelblau&#39;s function</span></span>
<span id="cb8-6"><a href="introduction-to-unconstrained-optimization.html#cb8-6"></a>Himm_grad<span class="op">=</span>grad(Himm)</span>
<span id="cb8-7"><a href="introduction-to-unconstrained-optimization.html#cb8-7"></a><span class="bu">print</span>(<span class="st">&quot;gradient vector at x_star:&quot;</span>, Himm_grad(x_star))</span>
<span id="cb8-8"><a href="introduction-to-unconstrained-optimization.html#cb8-8"></a></span>
<span id="cb8-9"><a href="introduction-to-unconstrained-optimization.html#cb8-9"></a><span class="co"># Hessian matrix of the Himmelblau&#39;s function</span></span></code></pre></div>
<pre><code>## gradient vector at x_star: [0. 0.]</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="introduction-to-unconstrained-optimization.html#cb10-1"></a>Himm_hess <span class="op">=</span> jacobian(Himm_grad)</span>
<span id="cb10-2"><a href="introduction-to-unconstrained-optimization.html#cb10-2"></a>M <span class="op">=</span> Himm_hess(x_star) </span>
<span id="cb10-3"><a href="introduction-to-unconstrained-optimization.html#cb10-3"></a>eigs <span class="op">=</span> np.linalg.eigvals(M)</span>
<span id="cb10-4"><a href="introduction-to-unconstrained-optimization.html#cb10-4"></a><span class="bu">print</span>(<span class="st">&quot;The eigenvalues of M:&quot;</span>, eigs)</span></code></pre></div>
<pre><code>## The eigenvalues of M: [82.28427125 25.71572875]</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="introduction-to-unconstrained-optimization.html#cb12-1"></a><span class="cf">if</span> (np.<span class="bu">all</span>(eigs<span class="op">&gt;</span><span class="dv">0</span>)):</span>
<span id="cb12-2"><a href="introduction-to-unconstrained-optimization.html#cb12-2"></a>    <span class="bu">print</span>(<span class="st">&quot;M is positive definite&quot;</span>)</span>
<span id="cb12-3"><a href="introduction-to-unconstrained-optimization.html#cb12-3"></a><span class="cf">elif</span> (np.<span class="bu">all</span>(eigs<span class="op">&gt;=</span><span class="dv">0</span>)):</span>
<span id="cb12-4"><a href="introduction-to-unconstrained-optimization.html#cb12-4"></a>    <span class="bu">print</span>(<span class="st">&quot;M is positive semi-definite&quot;</span>)</span>
<span id="cb12-5"><a href="introduction-to-unconstrained-optimization.html#cb12-5"></a><span class="cf">else</span>:</span>
<span id="cb12-6"><a href="introduction-to-unconstrained-optimization.html#cb12-6"></a>    <span class="bu">print</span>(<span class="st">&quot;M is negative definite&quot;</span>)</span></code></pre></div>
<pre><code>## M is positive definite</code></pre>
<p>We see that <code>x1</code> satisfies the second order sufficient conditions and is a strong local minimizer. We wanted to perform the analyses using <code>autograd</code> package instead of <code>scipy.optimize</code>, because there might be cases when we need to use test functions that are not predefined in <code>scipy.optimize</code> package, unlike the <code>Rosenbrock function</code>.</p>
</div>
</div>
<div id="algorithms-for-solving-unconstrained-minimization-tasks" class="section level2">
<h2><span class="header-section-number">2.5</span> Algorithms for Solving Unconstrained Minimization Tasks</h2>
<p>An optimization algorithm for solving an unconstrained minimization problem requires an initial point <span class="math inline">\(\mathbf{x}_0\)</span> to start with. The choice of <span class="math inline">\(\mathbf{x}_0\)</span> depends either on the applicant who has some idea about the data and the task at hand or it can be set by the algorithm in charge. Starting with <span class="math inline">\(\mathbf{x}_0\)</span>, the optimization algorithm iterates through a sequence of successive points <span class="math inline">\(\{\mathbf{x}_0, \mathbf{x}_1, \ldots, \mathbf{x}_{\infty}\}\)</span>, which stops at the point where all the termination conditions are met for approximating the minimizer <span class="math inline">\(\mathbf{x}^*\)</span>. The algorithm generates this sequence taking into consideration the objective function <span class="math inline">\(f(\mathbf{x})\)</span> at a particular point <span class="math inline">\(f(\mathbf{x}_n)\)</span>. A new iterate <span class="math inline">\(\mathbf{x}_{n+1}\)</span> is added in the sequence if the condition <span class="math inline">\(f(\mathbf{x}_{n+1}) &lt; f(\mathbf{x}_n)\)</span>. Although in many special cases, the algorithm might fail to find a new point in each and every step following the above condition, it must satisfy that after some stipulated number <span class="math inline">\(k\)</span> of steps, the following condition is met: <span class="math display">\[f(\mathbf{x}_{n+k}) &lt; f(\mathbf{x}_n)\]</span>. One of the important terminating conditions, for example, is to check whether the first order necessary condition is sufficiently accurate, for a smooth objective function, i.e, <span class="math inline">\(\|\nabla f(\mathbf{x}_{\infty})\| &lt; \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is the infinitesimal tolerance value. We will discuss these conditions further in the subsequent chapters.</p>
<p>Fundamentally, there are two approaches available to generate <span class="math inline">\(f(\mathbf{x}_{n+1})\)</span> from <span class="math inline">\(f(\mathbf{x}_n)\)</span>:</p>
<ul>
<li><p><strong>Line Search Descent Method</strong>: Using this method, the optimization algorithm first picks a direction <span class="math inline">\(\mathbf{\delta}_n\)</span> for the <span class="math inline">\(n^{th}\)</span> step and performs a search along this direction from the previous generated iterate <span class="math inline">\(\mathbf{x}_{n-1}\)</span> to find a new iterate <span class="math inline">\(\mathbf{x}_n\)</span> such that the condition <span class="math inline">\(f(\mathbf{x}_n) &lt; f(\mathbf{x}_{n-1})\)</span> is satisfied. A direction <span class="math inline">\(\mathbf{\delta}_n\)</span> is selected for the next iterate if the following condition is satisfied:</p>
<p><span class="math display" id="eq:42">\[\begin{equation}
      \nabla^T f(\mathbf{x}_{n-1})\mathbf{\delta}_n &lt; 0 \tag{2.42}
  \end{equation}\]</span></p>
<p>i.e, if the directional derivative in the direction <span class="math inline">\(\mathbf{\delta}_n\)</span> is negative. Here <span class="math inline">\(f\)</span> is the objective function. In view of that, the algorithm then needs to ascertain a distance by which it has to move along the direction <span class="math inline">\(\mathbf{\delta}_n\)</span> to figure out <span class="math inline">\(\mathbf{x}_n\)</span>. The distance <span class="math inline">\(\beta &gt;0\)</span>, which is called the <em>step length</em>, can be figured out by solving the one-dimensional minimization problem formulated as:</p>
<p><span class="math display" id="eq:43">\[\begin{equation}
      \underset{\beta &gt; 0}{\min} \tilde{f}(\beta) = \underset{\beta &gt; 0}{\min} f(\mathbf{x}_{n-1} + \beta \mathbf{\delta}_n) \tag{2.43}

  \end{equation}\]</span></p></li>
</ul>
<div class="figure">
<img src="img%202.png" alt="" />
<p class="caption">Line Search Descent Method</p>
</div>
<ul>
<li><p><strong>Trust Region Method</strong>: Using this method, the optimization algorithm develops a model function [refer to Nocedal &amp; Wright], <span class="math inline">\(M_n\)</span>, such that its behavior inside a boundary set around the current iterate <span class="math inline">\(\mathbf{x}_n\)</span> matches that of the objective function <span class="math inline">\(f(\mathbf{x}_n)\)</span> at that point. The model function is not expected to give a reasonable approximation to the behavior of the objective function at a point <span class="math inline">\(\mathbf{x}_t\)</span> which is far away from <span class="math inline">\(\mathbf{x}_n\)</span>, i.e, not lying inside the boundary defined around <span class="math inline">\(\mathbf{x}_n\)</span>. As a result, the algorithm obstructs the search for the minimizer of <span class="math inline">\(M_n\)</span> inside the boundary region, which is actually called the <em>trust region</em>, denoted by <span class="math inline">\(\mathcal{T}\)</span>, before finding the step <span class="math inline">\(\mathbf{\zeta}\)</span>, by solving the minimization problem formulated by:</p>
<p><span class="math display" id="eq:44">\[\begin{equation}
      \underset{\mathbf{\zeta}}{\min\ } M_n(\mathbf{x}_n+\mathbf{\zeta}),\text{ where }\mathbf{x}_n+\mathbf{\zeta}\in \mathcal{T} \tag{2.44}
  \end{equation}\]</span>
Using this <span class="math inline">\(\mathbf{\zeta}\)</span>, if the decrease in the value of <span class="math inline">\(f(\mathbf{x}_{n+1})\)</span> from <span class="math inline">\(f(\mathbf{x}_n)\)</span> is not sufficient, it can be inferred that the selected trust region is unnecessarily large. The algorithm then reduces the size of <span class="math inline">\(\mathcal{T}\)</span> accordingly and re-solves the problem given by equation Eq.<a href="introduction-to-unconstrained-optimization.html#eq:44">(2.44)</a>. Most often, the trust region <span class="math inline">\(\mathcal{T}\)</span> is defined by a circle in case of a two dimensional problem or a sphere in case of a three dimensional problem of radius <span class="math inline">\(\mathcal{T_r}&gt;0\)</span>, which follows the condition <span class="math inline">\(\|\mathbf{\zeta}\| \leq \mathcal{T_r}\)</span>. In special cases, the shape of the trust region might vary. The form of the model function is given by a quadratic function, given by,
<span class="math display" id="eq:45">\[\begin{equation}
      M_n(\mathbf{x}_n+\mathbf{\zeta}) = f(\mathbf{x}_n) + \mathbf{\zeta}^T\nabla f(\mathbf{x}_n)+\frac{1}{2}\mathbf{\zeta}^T\mathbf{B} f(\mathbf{x}_n)\mathbf{\zeta} \tag{2.45}
  \end{equation}\]</span>
Where, <span class="math inline">\(\mathbf{B}f(\mathbf{x}_n)\)</span> is either the Hessian matrix <span class="math inline">\(\mathbf{H}f(\mathbf{x}_n)\)</span> or an approximation to it.</p></li>
</ul>
<p>Before moving into detailed discussions on line search descent methods and trust region methods in the later chapters, we will first deal with solving equation Eq.<a href="introduction-to-unconstrained-optimization.html#eq:43">(2.43)</a> in the immediate next chapter, which is itself an unconstrained one dimensional minimization problem, where we have to solve for <span class="math display">\[\underset{\beta&gt;0}{\min\ }\tilde{f}(\beta)\]</span> and deduce the value of <span class="math inline">\(\beta^*\)</span>, which is the minimizer for <span class="math inline">\(\tilde{f}(\beta)\)</span>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solving-one-dimensional-optimization-problems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/indrag49/Numerical-Optimization/edit/master/02-Unconstrained_Optimization.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/indrag49/Numerical-Optimization/blob/master/02-Unconstrained_Optimization.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
